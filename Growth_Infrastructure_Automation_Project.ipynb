{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c59d7f",
   "metadata": {},
   "source": [
    "\n",
    "# Scalable Growth Infrastructure & Automation (Portfolio Project)\n",
    "**Goal:** Demonstrate an end-to-end analytics workflow that integrates multiple data sources, applies data quality checks, builds KPI-ready datasets, and exports clean tables for BI dashboards (Power BI / Excel).\n",
    "\n",
    "**Tech:** Python (Pandas), SQL-ready outputs, BI-ready CSV exports  \n",
    "**Data:** Synthetic dataset (safe for GitHub) placed in `data/` folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57954f",
   "metadata": {},
   "source": [
    "\n",
    "##  Setup & Folder Structure\n",
    "\n",
    "Make sure your repository (or local folder) looks like this:\n",
    "\n",
    "```\n",
    "project-root/\n",
    "  data/\n",
    "    customer_data.csv\n",
    "    sales_data.csv\n",
    "    performance_metrics_daily.csv\n",
    "    sales_leaderboard_monthly.csv\n",
    "    data_quality_issues_sample.csv\n",
    "  notebooks/\n",
    "    growth_pipeline.ipynb   (this notebook)\n",
    "```\n",
    "\n",
    "If your files are somewhere else, update `DATA_DIR` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee2f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = Path(\"data\")  # <-- change if needed\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR.resolve())\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8986d67",
   "metadata": {},
   "source": [
    "## 1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f00599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "customers = pd.read_csv(DATA_DIR / \"customer_data.csv\")\n",
    "sales = pd.read_csv(DATA_DIR / \"sales_data.csv\")\n",
    "daily_kpis = pd.read_csv(DATA_DIR / \"performance_metrics_daily.csv\")\n",
    "leaderboard = pd.read_csv(DATA_DIR / \"sales_leaderboard_monthly.csv\")\n",
    "dq_issues = pd.read_csv(DATA_DIR / \"data_quality_issues_sample.csv\")\n",
    "\n",
    "display(customers.head())\n",
    "display(sales.head())\n",
    "print(\"customers:\", customers.shape)\n",
    "print(\"sales:\", sales.shape)\n",
    "print(\"daily_kpis:\", daily_kpis.shape)\n",
    "print(\"leaderboard:\", leaderboard.shape)\n",
    "print(\"dq_issues:\", dq_issues.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcbe142",
   "metadata": {},
   "source": [
    "## 2) Quick Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def profile_df(df, name):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(df.dtypes)\n",
    "    print(\"Missing values (top 10):\")\n",
    "    display(df.isna().sum().sort_values(ascending=False).head(10))\n",
    "    print(\"Duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "profile_df(customers, \"customers\")\n",
    "profile_df(sales, \"sales\")\n",
    "profile_df(daily_kpis, \"daily_kpis\")\n",
    "profile_df(leaderboard, \"leaderboard\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6059ce",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Data Quality Checks (QA/QC)\n",
    "\n",
    "We run common checks:\n",
    "- Missing values\n",
    "- Duplicates\n",
    "- Join integrity (sales must map to a customer)\n",
    "- Outlier review (revenue)\n",
    "\n",
    "We do not delete suspicious rows silently — we **flag** and **document**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.1 Type fixes\n",
    "sales[\"date\"] = pd.to_datetime(sales[\"date\"], errors=\"coerce\")\n",
    "customers[\"signup_date\"] = pd.to_datetime(customers[\"signup_date\"], errors=\"coerce\")\n",
    "\n",
    "# 3.2 Join integrity\n",
    "missing_customers = sales.loc[~sales[\"customer_id\"].isin(customers[\"customer_id\"])]\n",
    "print(\"Sales rows with missing customer_id match:\", len(missing_customers))\n",
    "\n",
    "# 3.3 Duplicate transactions\n",
    "dup_tx = sales[sales.duplicated(subset=[\"transaction_id\"], keep=False)]\n",
    "print(\"Duplicate transaction_id rows:\", len(dup_tx))\n",
    "\n",
    "# 3.4 Revenue outliers (simple IQR rule)\n",
    "q1 = sales[\"revenue\"].quantile(0.25)\n",
    "q3 = sales[\"revenue\"].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "outliers = sales[(sales[\"revenue\"] < lower) | (sales[\"revenue\"] > upper)]\n",
    "print(\"Revenue outliers flagged (IQR):\", len(outliers))\n",
    "\n",
    "# Save QC findings\n",
    "qc_summary = pd.DataFrame({\n",
    "    \"check\": [\"missing_customer_match\", \"duplicate_transaction_id\", \"revenue_outliers_iqr\"],\n",
    "    \"flagged_rows\": [len(missing_customers), len(dup_tx), len(outliers)]\n",
    "})\n",
    "qc_summary.to_csv(OUT_DIR / \"qc_summary.csv\", index=False)\n",
    "qc_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818eef04",
   "metadata": {},
   "source": [
    "## 4) System Integration: Build a Unified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ccd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge sales + customer master data\n",
    "df = sales.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "# Basic cleaning / standardization\n",
    "df[\"revenue\"] = pd.to_numeric(df[\"revenue\"], errors=\"coerce\")\n",
    "df[\"approved\"] = df[\"approved\"].astype(int)\n",
    "df[\"processing_failure\"] = df[\"processing_failure\"].astype(int)\n",
    "df[\"disputed\"] = df[\"disputed\"].astype(int)\n",
    "\n",
    "# Add time features\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "df[\"day_of_week\"] = df[\"date\"].dt.day_name()\n",
    "\n",
    "display(df.head())\n",
    "print(\"Unified dataset shape:\", df.shape)\n",
    "\n",
    "df.to_csv(OUT_DIR / \"unified_sales_customer.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84916197",
   "metadata": {},
   "source": [
    "\n",
    "## 5) KPI Tables (SQL-ready Outputs)\n",
    "\n",
    "We create:\n",
    "- Daily KPI table\n",
    "- Monthly KPI table (by region/channel/product)\n",
    "- Leaderboard rollups (monthly)\n",
    "\n",
    "These outputs can be loaded into Power BI or used to build SQL views.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5.1 Daily KPIs (recomputed from unified data)\n",
    "daily = df.groupby(df[\"date\"].dt.date).agg(\n",
    "    total_transactions=(\"transaction_id\", \"count\"),\n",
    "    total_revenue=(\"revenue\", \"sum\"),\n",
    "    approval_rate=(\"approved\", \"mean\"),\n",
    "    processing_failure_rate=(\"processing_failure\", \"mean\"),\n",
    "    dispute_rate=(\"disputed\", \"mean\"),\n",
    ").reset_index().rename(columns={\"date\":\"date\"})\n",
    "\n",
    "daily[\"total_revenue\"] = daily[\"total_revenue\"].round(2)\n",
    "daily[\"approval_rate\"] = daily[\"approval_rate\"].round(4)\n",
    "daily[\"processing_failure_rate\"] = daily[\"processing_failure_rate\"].round(4)\n",
    "daily[\"dispute_rate\"] = daily[\"dispute_rate\"].round(4)\n",
    "daily[\"revenue_7d_ma\"] = daily[\"total_revenue\"].rolling(7).mean().round(2)\n",
    "daily[\"approval_7d_ma\"] = daily[\"approval_rate\"].rolling(7).mean().round(4)\n",
    "daily[\"month\"] = pd.to_datetime(daily[\"date\"]).dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# 5.2 Monthly KPIs segmented (region/channel/product)\n",
    "monthly = df.groupby([\"month\", \"region\", \"channel\", \"product_tier\"]).agg(\n",
    "    total_transactions=(\"transaction_id\", \"count\"),\n",
    "    total_revenue=(\"revenue\", \"sum\"),\n",
    "    approval_rate=(\"approved\", \"mean\"),\n",
    "    dispute_rate=(\"disputed\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "monthly[\"total_revenue\"] = monthly[\"total_revenue\"].round(2)\n",
    "monthly[\"approval_rate\"] = monthly[\"approval_rate\"].round(4)\n",
    "monthly[\"dispute_rate\"] = monthly[\"dispute_rate\"].round(4)\n",
    "\n",
    "# Save outputs\n",
    "daily.to_csv(OUT_DIR / \"kpi_daily.csv\", index=False)\n",
    "monthly.to_csv(OUT_DIR / \"kpi_monthly_segmented.csv\", index=False)\n",
    "leaderboard.to_csv(OUT_DIR / \"leaderboard_monthly.csv\", index=False)\n",
    "\n",
    "display(daily.head())\n",
    "display(monthly.head())\n",
    "print(\"Saved KPI outputs to:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2cfc66",
   "metadata": {},
   "source": [
    "## 6) Simple Visualizations (Trend & Monitoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785db71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Revenue trend\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(pd.to_datetime(daily[\"date\"]), daily[\"total_revenue\"])\n",
    "plt.title(\"Total Revenue (Daily)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.show()\n",
    "\n",
    "# Approval rate trend\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(pd.to_datetime(daily[\"date\"]), daily[\"approval_rate\"])\n",
    "plt.title(\"Approval Rate (Daily)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Approval Rate\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Monthly revenue by region\n",
    "monthly_region = df.groupby([\"month\", \"region\"]).agg(total_revenue=(\"revenue\",\"sum\")).reset_index()\n",
    "pivot = monthly_region.pivot(index=\"month\", columns=\"region\", values=\"total_revenue\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(pivot.index, pivot.values)\n",
    "plt.title(\"Monthly Revenue by Region\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Revenue\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493fd8b9",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Optional: Example SQL Views (copy/paste)\n",
    "\n",
    "If you load the exported CSVs into a database, these are example views you can create.\n",
    "\n",
    "> Note: SQL syntax may vary slightly by database (PostgreSQL, SQL Server, Snowflake).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "-- Example: Daily KPI view\n",
    "-- CREATE VIEW vw_kpi_daily AS\n",
    "-- SELECT\n",
    "--   date,\n",
    "--   total_transactions,\n",
    "--   total_revenue,\n",
    "--   approval_rate,\n",
    "--   processing_failure_rate,\n",
    "--   dispute_rate,\n",
    "--   revenue_7d_ma,\n",
    "--   approval_7d_ma\n",
    "-- FROM kpi_daily;\n",
    "\n",
    "-- Example: Monthly segmented KPI view\n",
    "-- CREATE VIEW vw_kpi_monthly_segmented AS\n",
    "-- SELECT\n",
    "--   month,\n",
    "--   region,\n",
    "--   channel,\n",
    "--   product_tier,\n",
    "--   total_transactions,\n",
    "--   total_revenue,\n",
    "--   approval_rate,\n",
    "--   dispute_rate\n",
    "-- FROM kpi_monthly_segmented;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ea945",
   "metadata": {},
   "source": [
    "\n",
    "## 8) What to Upload to GitHub\n",
    "\n",
    "Upload these folders/files:\n",
    "- `data/` (CSV files) — optional if you want the data public\n",
    "- `notebooks/` (this notebook)\n",
    "- `outputs/` (generated KPI tables)\n",
    "- `README.md` (project explanation)\n",
    "\n",
    "If you keep the data private, include instructions in the README for how to generate/download the data.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
